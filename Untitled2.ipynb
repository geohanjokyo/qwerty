{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 1.5.1+cu101 _CudaDeviceProperties(name='GeForce RTX 2060 SUPER', major=7, minor=5, total_memory=8192MB, multi_processor_count=34)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from IPython.display import Image  # for displaying images\n",
    "from utils.google_utils import gdrive_download  # for downloading models/datasets\n",
    "print('torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 21332), started 0:21:07 ago. (Use '!kill 21332' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-964386424e1e13c0\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-964386424e1e13c0\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start tensorboard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apex recommended for faster mixed precision training: https://github.com/NVIDIA/apex"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-29 00:47:27.186769: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 469, in <module>\n",
      "    train(hyp, tb_writer, opt, device)\n",
      "  File \"train.py\", line 186, in train\n",
      "    world_size=opt.world_size)\n",
      "  File \"C:\\Users\\kimsu\\yolov5\\utils\\datasets.py\", line 59, in create_dataloader\n",
      "    pad=pad)\n",
      "  File \"C:\\Users\\kimsu\\yolov5\\utils\\datasets.py\", line 342, in __init__\n",
      "    labels, shapes = zip(*[cache[x] for x in self.img_files])\n",
      "  File \"C:\\Users\\kimsu\\yolov5\\utils\\datasets.py\", line 342, in <listcomp>\n",
      "    labels, shapes = zip(*[cache[x] for x in self.img_files])\n",
      "KeyError: 'train\\\\images\\\\00a1516575768.jpg'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using CUDA device0 _CudaDeviceProperties(name='GeForce RTX 2060 SUPER', total_memory=8192MB)\n",
      "\n",
      "Namespace(batch_size=16, bucket='', cache_images=True, cfg='./models/yolov5s.yaml', data='./data.yaml', device='', epochs=100, evolve=False, hyp='', img_size=[2700, 2700], local_rank=-1, multi_scale=False, name='tutorial', noautoanchor=False, nosave=True, notest=False, rect=False, resume=False, single_cls=False, sync_bn=False, total_batch_size=16, weights='yolov5s.pt', world_size=1)\n",
      "Start Tensorboard with \"tensorboard --logdir=runs\", view at http://localhost:6006/\n",
      "Hyperparameters {'optimizer': 'SGD', 'lr0': 0.01, 'momentum': 0.937, 'weight_decay': 0.0005, 'giou': 0.05, 'cls': 0.58, 'cls_pw': 1.0, 'obj': 1.0, 'obj_pw': 1.0, 'iou_t': 0.2, 'anchor_t': 4.0, 'fl_gamma': 0.0, 'hsv_h': 0.014, 'hsv_s': 0.68, 'hsv_v': 0.36, 'degrees': 0.0, 'translate': 0.0, 'scale': 0.5, 'shear': 0.0}\n",
      "Overriding ./models/yolov5s.yaml nc=80 with nc=101\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1     41022  torch.nn.modules.conv.Conv2d            [128, 318, 1, 1]              \n",
      " 19                -2  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 20          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 21                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 22                -1  1     81726  torch.nn.modules.conv.Conv2d            [256, 318, 1, 1]              \n",
      " 23                -2  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 24          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 25                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 26                -1  1    163134  torch.nn.modules.conv.Conv2d            [512, 318, 1, 1]              \n",
      " 27      [-1, 22, 18]  1         0  models.yolo.Detect                      [101, [[116, 90, 156, 198, 373, 326], [30, 61, 62, 45, 59, 119], [10, 13, 16, 30, 33, 23]]]\n",
      "Model Summary: 191 layers, 7.52479e+06 parameters, 7.52479e+06 gradients\n",
      "\n",
      "WARNING: --img-size 2700 must be multiple of max stride 32, updating to 2720\n",
      "WARNING: --img-size 2700 must be multiple of max stride 32, updating to 2720\n",
      "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
      "Transferred 362/370 items from yolov5s.pt\n"
     ]
    }
   ],
   "source": [
    "!python train.py --img 2700 --batch 16 --epochs 100 --data ./data.yaml --cfg ./models/yolov5s.yaml --weights yolov5s.pt --name tutorial --nosave --cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geohan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
